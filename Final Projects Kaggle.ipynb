{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb24b220>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb384dc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAE5CAYAAAA3GCPGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5hlVZW339U0GZsgUZEgmUEJgpI+sg46oIgECQZEcRQBRUVxVBBHUUQHBEFBQEGiEgQlZ0GCDXQ3eUQawQCOAtKihMb1/bH26Tp16+Sq6tONv/d57lN1z9377H3SOnuvvYK5O0IIIWYvE/rugBBC/Csi4SuEED0g4SuEED0g4SuEED0g4SuEED0wsWnBzXe8QWYRQgjRkpsu2dKKtmvkK4QQPdB45CvEIIdevl9tmSO3P6m2XlEZIV7uWFMnC6kdhBCiPVI7CCHEHISErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9MDEvjsg5l4OvXy/2jJHbn9Sbb2iMkK83DF3b1Rw8x1vaFZQCCHELG66ZEsr2i61gxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9ICErxBC9MDEvjsg5m4OvXy/yt+P3P6k2jpFZYR4uWPu3qjg5jve0KygEEKIWdx0yZZWtF0jX9GZulEvaOQrRBka+QohxDhSNvLVgpsQQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAhK8QQvSAsheLzih7sRDdUfZiIYQYR5S9WAgh5iAkfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogcUWEd0RoF1hOiOAusIIcQ4osA6QggxByHhK4QQPSCdr+iMdL5CdEc6XyGEGEek8xVCiDkICV8hhOgBCV8hhOgBLbiJUdFl0a2ojhbdxL8aWnATQohxRAtuQggxByHhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPSDhK4QQPaAcbqIzXfK3FdVT/jbxr4hyuAkhxDiiHG5CCDEHIeErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBA9IOErhBB94O6tPsB+bet0rTe76rxc25rT+6dzMff0T+dibOoN20eHRid37GzrerOrzsu1rTm9fzoXc0//dC7Gpl7+I7WDEEL0gISvEEL0QBfhe1LHtrrUm111Xq5tzen9m51tqX9zT1tzev9GU28WlvQXQgghZiNSOwghRA9I+AohRA9I+Io5FjNboe8+CDFeSPiOE2a2RNWn4T4OarKtb8xs4XHa9UW5Ns5vU9HMJpjZpmPfJTGW/Cu/YBstuJnZZsAUd3/WzPYGNgCOdfffNqi7DrA2sEC2zd1PLyk7AZjm7us07H++7orAau5+tZktCEx09xlt9zNWmNl0wAEDVgCeSv8vBjzq7is32Med7r7BwLa73H39mnr/Afwbw8/5ETV1NgMOB1YEJqa+uru/tqLOpsD3gUXcfQUzWxf4sLt/tPLAGpI/1ibHXVD/FnffpGHZjd391i79zO1jU2Al4vwB5fd6Kj8/8K6COoXXyszuJu6pET9FNX99RVurAL9z9+fNbCvg9cDp7v50n/3L3+Nmdr67v6usPyVtrg58mqH7NuvjNgVlD67al7t/q6IdA/YCXuvuR6SXxrLufnub/uaZWF8EgBOBddPDdQhwCnA6sGVVJTM7DNiKEL6XAm8Fbkp1R+Du/zSzqWa2grs/2rBvmNmHgP2AJYBVgOWB7wLbFpR9HXAy8GrgMuAz7v5U+u12d39jSRszqL6xJg0cy8qp3neBi9390vT9rcB2NcezB7AnsLKZXZz7aRLwl5q63wUWArYmBOMuQJMb5BTgE8AdwEsNygP8D/DvwMUA7j7VzLao6Fvbc+8l/zflSjN7F3CB148yTiAGFa2EdoaZnUHce1MYOn9Oyb2e+CnwV+KcP9+gmR3a9GmA84ENzWxV4lpfDJwFvK3n/lnu/9IXfQU/Jp71k6m/b1/RYf8ZJwD/BLYBjgBmEOd0o857bOhKd2f6+0Vg3/y2mnp3E6qNqen7MsAlNXWuTQd2DXGDXEwIr6o6U4D5gLvybZeUvQnYnhiBfgq4F1gl/XZX3TF1cEO8o2BbpWsi8RbfCriFeMFlnw2IEX1V3WkDfxcBrmzQz9s6HNttg+ctu9Zjce6Jh+mZdD/MzP0/A3imQf9mEA/MC7m6hfUGjqH1fQDcT5pJtqhzz1jfbxVtZc/wp4EDmhzn7OhfXo40kSkF9Uc8X+N8/hrd600+TUe+M8zsUGBvYAszmweYt0G9f3iMZmea2STgT9S/3b7UsE95nnf3F2JmAGY2kfKR0iLufnn6/2gzuwO43MzeU1FnBGa2NMOn9WUj9T+b2eeBH6X9703N6NVDnfNbM9uOoXO4OrAm8UKr4h/p79/N7FWprVoVB3CdmX0DuIDcKMfd76yo81iaaruZzQccSAihMlqde3efp0G/S3H3NiOdCWa2ODFYyP6fNSpz9ydr6t8DLAv8sUWbvzSz17l73TUdhpltDBwHrEUMOuYBnvWB2dcAL6YZ1fuAHdO2umd4dvRvXTN7hjjXC+b+h4IZZa6NbN3kEjP7KHAhw+/b0utlZgsA+zJSNfeBisN6Mck9T/tYinixd6ap8N2dmAbv6+6PJ33HNxrUm2xmixFTgjuAv1EzBXb3Gxr2Kc8NZvY54uK9GfgocElJWTOzRd39r6m969LU9HxCbVGJmb0d+CbwKuJlsiIhcP6tpMoewGHEzQFwY9rWhBuB/5cEwTXAZOJa7FVR52fpnH8DuJO4Wb7foK03pb8b5rY5Mc0q4z+BYwk1wu+AK4H9K8q3OvdmthDworu/mL6vQUyTH3H3CwfL5+qt6e4PmNkGRb+XvFAWJe7R7MHPl3FKBg1mdkn6/RXAfWZ2O8OFwNsL6mS60YnAPmb2cKpTq7tNHA+8m5hybwi8F1i1ps4+xPX6irtPN7OViQFB0THNtv6N4gV7B0NrKhAj+lm7pXqQdwbwAKEyO4J4nqoGDQDfJp7hZczsK4Q67/Ptuz1E0wW3hYHn3P2l3AjssuyhaNSQ2UrAJHefVlMur1udj3g7V77V00LdvsBbiItxBfB9Lzg4M9sTeNgHFlfSC+UL7v6hmv5NJQTS1e6+vpltDezh7vtV1etCthhhZgcAC7r7UW0WntKCyQKZsBvjvs0D/NDd925Rp9W5N7MbiRf+r5Ou8nbgTGIN4Vfu/tmSdk5y9/3M7LqCn90LFmO6YmaV6x5FgwmLxeGqOpUL2WY22d03NLNpmSA0s1+6e6V1h8VC9Aru/mBNudnWv64v2NGQPUNZ/8xsXuCKuvvCzNZkaB3pWnevE9jVNNWrEIs4rwYeI94AZzaoZ8Q0+4vp+wrAG1vqWnYCvtqg3HzECu7rgPlGo4upaWdy+jsVmJD+v72g3CXkdNaDn4Zt3QVsAtwK/FvaVqjLztVZCPgCcHL6vhqwQ4O2FgW+RYyuJxOj+0Vr6lwxmnMNLFzz+925/78MfCd3rSvPQ8U+5y3ZvmL+eIkFy2OJRcjaYwS+3mTbwO9nNNlWUObGdA5OB45KfazUPxKqhgeB6en7enX3IbGAOH/6fytCrbTYWPYvlV0t/b8q8CShsrgG+FqDtvbP9wlYHPhoTZ3bc22vAyxJDArq2tognYMDgA263H/5T1M7X3P3vwM7A8e5+zspn2bnOYEQHtk0ewbwnYZtAuDuF1E99c1Mq35DTA2OBx5KVgVVdVY3s5PN7Eozuzb7NOjS02a2CHHhzjSzY4nFoEGOJgTYdEIPe3L6/I3QDzbhIOBQ4EJ3v9fMXgsUjebynEZMEbPV+t8B/92grVOJ67Nb+jyT9lXFI8DNZvYFMzs4+9Q1ZGabmtl9pKmema1rZicUFM3PXLYBrgJw9xdooW+zYBsz+z5xPoo4D1g4lV+PmDI/Sgipor4N8uaCbZX3IAPPUJpNvKFBW+8h9KgfA54FXkOYhFVxOPBG4GkAd59C/VrA+cBLOQuJlQkLibHs3+Lu/uv0//uAs939AOLc/UeDtj7kOXM5D+uZytkrcFJS5X2BGAzdB3y9qoKZfRH4IaEeWxI4La3ldKeJhKbDCCyVab1CSAj47LML8DXglpo6DwCrDryxH6ipMxX4CHFDviH7NDimhYkbayJxsxwIvLJqFNBk21h9GBqZt1qVJey4a7cN/H5Y0adBW7cRD2S+jyNW1gmd5NHAwcATwEJp+2INj+lNxOj1UeKl9z7iYS8qOy33/9HAUen/CfnfCup9hFgEfRaYlvtMp2R2SLxQ8xYcmSXGX4Ajx+m+KLJMKT2u9Hv2/B5CQwuJDv3Kn/ebgZ1a3rfTyFmZpGfz3pKy9wH/RbKwadnP+wkVXvZ9QeD+0Rx70wW3LiMw6LZCuGPu/5nE6OodNXX+5O4P5b4/TCyGVTHT3U+sKTMCd3829/WHDaosZWavdfeHAdJCx1Jt283I9JkVRV5Iur3snK9CMxvNf5jZ5u5+U6q3GUOWE4W4exfLlKzuY2Z5E89CG80PEffeCsBbPGZfEDrfo8v2nRZEdiOE7tnEospkd6+6XvnObEPc73hYmlQdylmEzfKRQF4HPcNLVtzd/UjgSDM70t0Prdp5YUeHHHgG91u1yHRP0rnPY2arEYOGX9Y0lVlIvJfmFhJt+zfNzI4Gfk+oHa5M+1isrp3ElcB5FvbtTiwqXl5Sdg9iIfBKM/szcW+c6+5NLFQeISwjnkvf5ydm250Z15CSZrYXsTq/ASGodgE+7+4/HuN2TiR0ducRF2BXQr91M4C7X1BQ53BCQDc2UUn1Wi0Imtn2ROzPh9OmlQgvsCsq2iizujBiNLB8Rd03E6uwaxM35mbA+939+rI6qd56xDVaNLXzZKo3taLOdRQ/ZHVqop8Q+uXjgY0JQbChu7+7pPxB7n5s3bbcb/9HXP9jgJ+5+3Nm9nCVcErqo+WAxwlBs7q7v2hmyxG26RuW1R3YT1MTxKz84oRePl/nxpo6r8x9XYC435dw9y9W1FmIGPW9JW26Avhvd3+uos7ahDC7xd3PTgOH3d39a2PVvzRQOIg496dm95uFCeMq7n5GTVsGfJhwXDLinv++u1c6XFiYw+1OqEMeItQdJ1eUv4hwqLiKuOffTNit/wnA3Q+saq9wn02EbxqxHsJIu7jShyxZIGxMPMTbEifmGq9ZITSz5QmF+2bEQd4EHOTuZbo6zKxKN+leYL+X3s5FZVt52ZjZTsQi4ucqysxPWIhAqEgWc/cnKsq/BPyW4aOxzKzm1e4+X0m9CcQL7hri3Btwq7v/ucXxTAJw92calM3rJxcgbuSZ7n5ITb0lCXXAdsS0/griGhfaP1tLN+s023oLMdLZhpilbQe8xt2L9PPZQ7w7Yav7Y3f/fdq+PrB01csylduReKEMM0F099K1ETP7ICF4licchTYmBF1rawwzu8ndN29bb3ZR1z8ze4O73zGwbUd3LzMZze73TuEIcvvYivDUXNvd568o976q/dTMqkorNdF3XEmYct1PeFqdSs1KbqpXqastqXMVYZM4MX3eD1w1Gt3KeH8IAVdXZlHgA8DVwO9ryv6aMAkq+u2xmrqt9MnA3unvwUWfDufihjE8r3sQViNPMdxa5DrC1K/JPhYgXkjnE3rjsyrKztN0vwV1pwKvJOlECWuJk2rq3J36NyV9X5OYBte1tUHusyExOq1bS7mKkVYBV5SUPS/Xv2mDn3Hq353A6waufa3XJWF6WPisVNTZiHhR/ha4gdDbL1lTZweSddNYfZrqfF/p7qekqd4NhFNDE2eINr71GUu5e34k+wMz+3hVhY6j5XmJk57FIrge+J7X2C6b2c65rxOIm6vw2NKU6u2Eg8oGhCH+ToSlRBXHEA9H0ZT1qJq6V5nZp4BziUUgoFKdkkUkK/IGq7xmA+qRCcSi5bI1/SOtGRxLjPSccKP+hCe9eI5fEh5jSxKWIxkzCEFQi8e0+ifAT8zsFcRCblnZl8zs75ZzBGnBi+7+F4toahM8HEgqV9AJ2/nnzAwzm9/DMWSNBm3lz0W2LrJbTZ0lfcAqIKlIisgi53WNJdGlf7sQ12gvYHNCz/yW6ipAqCvutXBuyd/vRc4tXyVmN08B5wCbVcmIAd4NHGsRXe80H62NL8093DKB9EcLs64/EFOlOg4mHu6ZZvYcFAehGeDPFpHTzk7f96DGHZcwiTqL0C1B2BafRrH5T8aJhL42MyN6T9r2wZq2Gi0ImtmZhGC/ktBtXgs85DW6VwB3/056iDd1918O/HZcTfVMxZL3NHNKPH7c/Xvp36vd/eaBY9ispq28l9FMYoV/35o6ENfqO8A70/d3E9f7TflCntysSWZzSSWS3bOTCJXWCKyBuVsFzwF3m9lVDH+Y63R6gyaIf6LYBDHP79LC0kXES/Mp4tmqxN23ritTwD8tF7DKwpGi8OXqaQHKG0QtHKv+ufvDZvZu4lw8RiywVi74Jtos+j4PvNXd/7dD//ZO998ehJmZEzLmbO8YPbGpzncH4BeEedBxxI3/JXe/uLJilw6Ft9PxxAPnxOjnQK9YuDCzKe6+Xt22gd+nuvu6ddu6YuEJZ4Sh+bkeq/uViz4F+2gdXatkP/N52MZWlSnSq47YNhaY2W3u/qaBbbe6+8Yl5fcjnCz+QVjLVIa7tIimV4pXWGmU6fa8Rqdn4QX6D2IGsBehZjrTS/TYBfW3THUur7pWSQf9SWJBFcIh5ih3f8jMJnq5Tjtb+M1mrFsA+3n1wu/OhP3r0sQ5rx08te2fjQxDuTQRSe15orE6V2bMbBmGoovd7u6Vlk5mtj9xbZ5O3xcnvFRr7bnTesXewMcJNeyqwLcbDIpGMpY6jBqdySrEamtlpCRiKlC7beD3q9MJmSd99iYW9+p0TKvkvr+WmqhKxAj3ZmLE9SQxqt08/TbCG4zQ4R1BrLz/Avg/IgZo03P2JWIRq1W0rFTXiMWm7wNPVJTbhHhYHmO4vvdw6vV0uwKvSP9/ngjKU+v5Q9huf5aw/FiRWMz9AmHAvkRB+V9To5Obkz6EmqTxNSO8EjckVG5V5bKV+Q8Q3pzrpv+npOtYd88vSagSdmxyPlNba7U4jtb9S9e/9NOgzd2I2dEPiYHOdGCXmjpFNu2F9svAzunvjoRl1DQijsTSuWv32073SU0njyO8xgo/DU7McoRr4e3EdO4wckr1kjojBGDRtoHfVyAWYv6PWGm+qO7CERYYjxK63hsI9cHWFeU/SrzFtyFG/pPS/78k9Eh1gmpDQsn/KPDLhjdzFhLxRWpCIubqNHYsSOW3TNfljwx3ljiY5PZZUTcLW7k58XJ5B80WSaZXfEa4eRJ2mwu1vrljMWt/QrV0avYpKVu4uETNIhOht76eePGsT3gvPp7uw+1L6rw93W93EnEMphMOTI8D76s638BKBdtXSs9XpRs+sY7wRmLUuwWwRU35m1ue7879S+fxFbnvrwDe1KDNqSRBmL4v1eBZbOOYkTmanF52voBt296b7l6tduhqXmER3HwPQi98Xvr81CuyN5jZJsCmxHD+f3I/TQLe6WOkDhhoc35gDWKU+IC7lzojmNn9xAj8yYHtryRcVg/2Bk4byaRpC+8Wva1qv4OOBRcSjgVNwkliZit6Sx2fDQUoOZLweDyrygSsK2kqexrhGZe3ya7Uw5rZjwnTvj3JRa9y96L0TCtW7avs3JjZZOBzhMrgJEKneKtFEJazi85FUkntmupcB7zeQ+e5NDE6fF1JW/e5+9olvz3o7qWLdV3M2ixsn5clBjP58z7Cbn4M+ncXMWvy9H0Ccf9Wqr3M7O78+Ur1ppadw1TmG8QLIe+Y8Zi7f7Kg7Lio3qB+we1c4m30fwMdWpoYiZXxHWIFe093n5zq1CmX5yMCf09k+Mr7M8RK6AjM7DgqVuSLHk4z28bdrx2wWgBYxcxKb6y0vxELPB4r3L8dFLx1fWNI91aJRQjLWRYZ7v6zkqL7EeqNExlyLGhqYQIR//cbtLDlBn5vZt8jbGi/nl5mtfFCksA6lTD7Kk1jk+N7xILl3bSLobqqu+9qZu9w9x+a2VmETXERy3m3NEIT3T3zyjoi24eH5UJZnX96WvQxs+merDzc/U9mVrVI96IVZHlJL446L8aDCL3ore6+dXo51C1WTQL+znCrAydG+WPdP8sEL8zyLGxiEHC5mV3B0AL97kTWnCo+QzwvHyHnmFFSdk0zK7KsaRpes5S6g/s2MeUbPNlvJqaaHymp9yrizf6tpAw/jxq3RB8yYftBixHY5Ibl8mxJPMg7FvxWdWM9Y2br+oDHl0VqpSKzpKxvmxGLD+em77sSVgK1mNnXiAfmzLTpIAsX4KJQissy5FhwjIX32YJVizADnJn6uAMxEngfocapYjciM8XR7v60hTfYp2vqQFg37EPEe55MjGqvzD98A8x09y4WDJmVztMWuQQfJ0Y8RXRNI5R/GQyuzpcdTz5w+z9teOD2qpfXYcDVyWQqszTZiNCff6amn63N2tx9n5p9jmX/HjazA4nBA4Sab9D0sKiPn04Dqc2Jc3iS14SidPd/EqPe71qYSy7v5R5x0ymWFaOnRjdyX8VvhTqSgnLLEylj7iBWB+v0UqsT07crCSF5LRE7s6neaXEaLHYAKzfZlvttc0Kxf3i6GDsQI4dHSItuJfWuIxfGkHgJXdfwWKaRM+wmdFNNjNwbOxbk6tyRtZnbVuswQSyqfCx91m16nVLdCYT+8/fEgt+XKF5w+woxUlmOtChXVK6g3gfT/bAFQ/E+PlxStlMaIYpTHWXfXyypMz31p5HOu+B8n56epzuJwOC1551QQy2W7t8bifxsl5aUPST9LVzzadm/0xv2b2nC9vZP2T1LTpdbUH61dAz3EKPeV7e4ZtcTo/olCDXdHcC36u6Lsf7UdbI0ak/Vb7ky8w98X4OaqE20iDZG5JRbM2uLENRPpgu4XU07RQt7lfmgiNHlEYRQu4Awf6q0XiBUAUvkvi8OPNjwJpk2UHcJqhd/JgC7DWybRMUiTq7crenvFUQov/WB39TUOSjd/Eekz92k6FcN2ns9odt/MD3UbyKsLopWorsIqRHnosF9tzjhpZb931jQt/kwZCGzwFjut0X7WxIvvcI4xaT4z8TsZ8SnRTuLjOMx/IIIvLQGMbi7oEXdzAvxg4TJLGXPFXD8uB1DTSdvoCD4OTGVqHVjLRFwdZYLjRPiEQkYs0XD/YhR5jxE7qgRAc5TuTUJk5jfMDx85ftpOJpveZPsQ4yYf5A+05vewIQKIav7w1T33TV1OoWrJEbyixLBpa8jRgNvr6kzjVxAdMKhpurlcGV2jYn4E3sy8gXd+CFqcEyNzwUxg2k9Gs0L6KJP1T1e9yxUtNl4dtixfz/I/d/oXh2ovwkRvvHR9H1d4IQGx3QNyRSVeDl/vqL8lIHvjc8lMUhYLp2/jbJ7uabOMkRM48vS97VJyYS7fup0vp8mwrX9gCE9ZZaTqTACFYCZLUtkvVgwrVRn+qxJhF1cFW0S4r3g6UwQ+ZjO8dDd3F+hrF+DEDSLMVyXM4OKIMwFxuCzfqJC8e7up5nZZcTIzoHPuvvjZe0M1D3bzK4nXnZGpFqvq9vWvTj7PVvI+ysRl6AJxvBQkC8xPBjQIEumv7v6SFfirB8j3H/NbFfC+WCGRQDrDYAvu/tdNf1rfC7cfaWafZUxmEts2G4p9ix80SIY1PJm9u2CvtR502Xp0r9Pfbr0Lv3L38sH0Sx0ap5jiOfxYgB3n2pmW1RX4WRC3nwv1ZmWFkjLEgEsMCBbhskar078egQxw7vJ3X9l4e7+64ryEAOg0whfBYD/Je6rU2rqlVLr4ZYsG/YnRkQQ08zveIUXSTJRe6B8zCUAAB4qSURBVD8hqPOLYjOIt2qpRYG1iDZmZrcSU4cniOnrG9x9evrtAXdfc7BOru4m7n5L2e8F5Ves+t0rFgkHLBZu8IpITal8lwSQWd3G5y+Vb20xkqt7MDEVvZC46d9BXN9jSso/TEwRy9oqM2HKcm1tTsTNPRr4nA94yRXUa3MvVZoT1TzMrUheUtsR3mMjwix6vTfdHe7eJONFJ/LmVV1MrSx5MObNDq3Ge9TMfuXuGw3UKfVSteL8fBnuY5inr0v/mlBrypGE7GEWqcHXIlZ3K82D0s3zQzN7l7uf36ZD3tAuNfFxImjKUsD/5ATv24jsGyMws0Pc/ShgT4tA0YPtFwqbKuFaRYHFwoEWMRuqgmgfTKhRvlnwm1ORVqnl+YNRWGW4+7fSyDwLFbhPzWh0UWLWUTYKK3spZ6O7/wBOdPefWsRjrmMtH4hXa5E2vIjsXC9ADBoy9/DXE/bFheEQuwhtjxCf55jZ/V4RL7mC1unSU18zqwAHfuGRoquIbERuFIzOG4zMH7OIx+tJbhxIfXbgP1sE/vfU110Ix59CvEP8iOzZLxtw1BzXsxY2/Vn/NqbYyql5f+pGvqmhtxHTgd8QF2RlYtX4spp6ixFv9lmjPuAIr4gYZR2jjTXFUoxQa+nDb8ODqA/7iQp/92QjuJ6HeQsWsWbvKlNT5OpNADbxgWA3TUg3/krkXq7ufnpNneuIYCZZFtl5CR1t5U2ehM//I17KN9eMyjsZrJvZzwiLiO2IBdh/EDr9Ssebovbq+mBm5xDp1e9O39cBPuXu7y8p33oENprZRqrfanaT6pxAxCHI28P+xt33Lyhb+GzkGqobmefjNWd2tKXxmlOd1xJ67E2JqGPTgb2aDHqa3u9dn/1UdwPC+mMdYva/FOHG3Ci6XuE+GwrfB4gV0IfS91WAn1dN61O581NHs4N6D2F2UhrWzyLJ4bwDdV5y9xHRxqwmepW7f6vq99lBEr5bZaOSZFd4fZ3wTWVbB9YxszOIOBpTGBoxeoMH+kFC2Gf9XJywgKjySvoiMUI+n3jIdiICkRfq6ayj95tFFobtCS+6X1vYE7/Ok3NDQflszeFHxKJefs3huzXqqNZBmtoyWuHWsc17gXU8PfDp5X63VwR7z9Vd2Ienzxo3LAIUTfCGkcK63u8d+zaRIY/YB0c7IGwaUrJLjjSIwDX5rKVfMrMpNXU2GhjRXGvhjllE5gm3BjG1z6Ks7UhJzFwzu4TqUceIOKAl+2maLuZI4K40QjJiRN80b1eXeMgbElH5m5bP+FqunxDmSIfX1NkDWD+b2icVy52UL5K8p2WfAPDI3XaBmS1kZhsSgUwKBW/i34k1h+WJeBoZMwhX4CruTwOAHxH3yd7UT5kxs/eW9H3ECGy0wjW9jA4mgojvZ5GTbQ0v936EWBNZgbCegYhQWDlqs3D5P4XwPF3BwqHow+7+0Zp6IxYRiSn6ZHf/aUH5NQg1W/ZSvN8iV2GT0I+N73czq4zCWPTs20hP2IzVrcYjto5K4Ztr+F4zu5ThOdJ+1WD/rZMyEqmqV3H336Q6r6VkRddTaEAzu5LwC5+Rvh9OrAgXkSVe3Jmw2/1R+r4HYW5UicXi2TcZSBfDQBrwXB+7WCxkZPGQXzKzf1Cj4kjcQxxXk6SA+X7mrTKgmVXGI7RIKuju98Cs+6o2VGE6198mbLc/T7itPwGsZGafKRNio1lzIEwDP8JQQPEbGfK6qmKj3P8LEIGbMieDQizSc32G0LU3demGWHW/g5iiQ8QW+TFQJXxfSQi123P9vSUTSCWDji5WCxDHsiZDz+C7CLPQfc1sa3eflRwhCfgLCLXmScS9sD5wvZnt7PUu323u900IZ56zCT1+ZWbURJV3W9U6RS11gXVOq2rYC3KjDdTPvF0WTZueIuwGS9+4ZrYtcXM9TJycFYmFnFLdWlKLrOspMI5FjIGpNdPLG919i7ptBfWmEgteV3sEldmaiAVamlHYzF7PSJ1U54tW07/rgPWISHL5xZjaEb2ZvZo43/l+lmbdsI5JBc3sIWBHr8/n1ykATa7+/MSDv9LAMR1RVW8sMLNFgTOqznsaNJxLWIDMcul290pXXDOb7O4bWjtrgi2r9ukFgZ6sg9VCKnMtsX4wM32fSOh930yoOtbOlb2MSEl2fUF/P+vub61pq/H9ntZb3kwMtF4P/JwIfnRvVRvjReXI19v7dg/Wnwqsa7mkjBYpgUqFr7tfk02joD7aWOIM4HYzu5AQAu+kYsSR6JrSvVW6GDM7lbjQ9zIUB6DRG9PMjIjEtbK7f9nMXkMEgLm9otrhDY6hqK2vE4swg/2sSnl0YfpkXN+wuSfqBG+iawCajJ8S0907qA/sQmpnM+IcDr6EWiVWJQLSrFZTpmt6rhcsUlRl+ttVqDk+d7/BwlxyNXe/OtWfWKNb7WK1AKFvX5gha4CFgVd5pGka7Ocqg4I319+TGrR1eIMy2T5fImLVXJ5ezHsQI+wjvEEwdIssPoOBpzq/yBvpfNMIuMg0o3LkmyuXj4B2MDGdGWxjb2IkfkYSttPS9g+Z2bPuflbF/r9iZpfT3OQJIs7w9Ra2p5BSujc4nLbpYjb2kjB7DTiBEITbEK7MfyOm3hsNFjSz44kYDl1DVe5E6A0bCanEZT5g721ma7j7gzX1JpvZudSHKuwagCZjeXffvkG5PKcQ98Yd1DswzGJgLWECoUo4r6Za1/RchxFC5DUW6ao2I3TcVf37EKFXXYJYoFqecNTYtqLafxJWC68mVBtXMjw9VRlHAVOSui1b5/iqxWLa1QNlq4R/k0W+ycA/PKKgrU6oO0qtsJLQ/Q9C8K5EqLWaDIS+SziIbU04t+xCjLY709TaIb9otgAxsvxDlxVFM3vM3V9TsP0uIs7tjIHtk4hANJVG5WlKsQzDRyulqYdSnWEp3ZsIHmuZLsbMTgG+6e731e27oO6d7r5Bk2mfmR1EeB0uR0xlz3b3usXNfP3LCM+zv7Wo8yDwBXc/L33/JOFyWfmyKVFnjVBjmdkjDKUNKipfORpNI6fjPJmNNcEKUhw1rJef1s8kFgUrkzPaKNJzWdicbkycm1s9bIeryk8h4qXclruXhsXCHUssLFLemPp3u7sX5qZLg5dzin4iYnMsU9POHYSp4+JEQPrJwN/dfa+Csj8kTMUuI7xh72lxPJmjT/Z3EWIhvEmSz+J9NhG+BR2ZQOg8W3uRmNmj7r5CwfZpXmJ+VfVb+v0AYjTwBEMurl5VJ9VrZQ+bBPwV7r5d1X4H6mxBpD9/nBjlNY4Dama3EYsqv0pCeCnC9rbUXCtNLd+dPgsQiwvneM3KsYVZ4LqEf32jgOXpATuJWHBbhpiSfrKNAB9PzOw+wrZ1Og3PvYXFxjzEaCh/Hgrtly1CoL4//f8+HwczsZJ22+rnh+lvkx72zppz0cpqYaDu4oTaJT9FH9E/G71NcTZAOQBY0MOJotA00Mz+ydBoOi/4muSmy87frcRi/ZOE/rpOtVRKU1OzQVYjzFYKsWqHhAVLqs1rBfaEFum+56vpz0HElLlRssK030L7QCp0xd4ttfiphIlV20DgEFOiC4GlLTJV7ELkOivFwyj960Rw8/VT+4cRAqWKixky1WuEu/8xqXsOJY7t0CrBay09jGz0Lr+VizUlZKPeDfNNUe5VmJ+FNIqDUHb8sxqrt8nuop+/wcw+R8RAeDMRL7fSzZ0WVgsD/SvMmkHBORyDl5VZWEzsxVDm7MJ73d2bqKrK+JmF09hRDHl+lgVgb0RTnW8mTC39fZyK4Mju/oqy3yo4BfiJmX3E3R9J7a5E6Djrglc8RntXv672sG1Tiz/aZBpZhLufmaZV2xLnfqe6hSoLz7TtiZHvtoRXYV3Ggk4PQToHfySmcssDp1pYjJTFb8hUL02D4Be5V2dUullDvIgs4kGs5mFKtxRhs1qIRXaH/yam5n/Lba8S4u2njsOP/0vEy7ENXfTznyHioNxNrG1cSr3wWBXYxoesFk4kZ7VQUa9x1gwbvd39QcTL/0J3v9fCNLXK67AVZrYRkWLoy+n7IsSxP8DwdGft991F7TBemNl/Eicye0D+BnzNa3KjJb3qGoTpSH6qWOrhZpHf60B3b2UPWzZNKhNeFm6dixGjjNo8WAN1z3D399RtS9szE5odCBvGc4CLBmcSFW1Np3g0WuWyupPn4gOkqeyh2Y1aUH62TtEtUshvSAiq1c3sVYQH3mYFZQ8kFpPuJ0yXDsqm1lbhkpzTWRoxGh2mv2wwim3t9ddWP5/UhNPcfZ3awsPrPUiElP1r+r4o8WJas6rfNhSEZgqRBPP5ClVApisvtLt39zqnmPy+Fgee7jCgqtrnnURs8CeTCvEc4ADiHlnL3QtTnDWhzsliReJgspO/NfHWfYSIbPZC14aLcPcstccixIuhkYshEY3+UUI9UaeiyFgSuM/C6LyxPaxHLrAFCe+iulV9CDXL8zTPg5VnmONG0jmXLTx+joj+/ymvCbBSQn6avQBhX7tEUUFLUdfc/SKLlDTPA7j7zDQaLqNzqEKLGAuDzgh15oTvJAz270zl/5DUWEV8iIiK97c04/qJma3k7sdSvOCXkU+b1CWtVWNBkVNX/J2wJmikn/ewBJhqBfnVamhjtZDnd2mKfhER1vMpwpKjqG83pGP7sg+3sb/EzKp02F8EzvOI/jc/sYi2HjDTzPZ096r+tWGe3PO0O5Gm6HzgfKv31q2kTu1wHnED/9XM1iN0P0cSB3kCMY0ZE6wgToPlEhBWjWI9ebq15PAOdTCzHQkvufmAldN5OaJMaHsHW2kzO5QQpguaWWamZ8ALRNzTona2TnVXsTDNe97MtiIE3ulek6iyQF9+jJndREHIQ0LIZyPBW3L/Qy4X2liRRrBbEcL3UkKXexP1ttwvuLtbSiSahEYZ82QjSXd/JJ27n6QBSKnwzUbvZraruw/zqrSIQzyWZML9Dlrq5wkrmHvTYCOvLisdbHjYIF/KkNXC53zIaqE0V5+7vzP9e7iFE8SihGlcFW3t7ncnzC8hnFMmpPKrEy/1MRO+NpQHcVvCXC+j65pZo8oL5k723sCp7v7NNI0ZldQvoHWchoykyzuEFpl3PYy4l2HIZvZ2r4hRnONw4ma8Pu1nSrpRyvq2OuGeuoy7r2Ph7fZ2Lwk+k/Z5JHCkmR3p1aEnizgf2NDMViV05RcTwvJtVZUGFrcmECPhslGilfxf9D1P11CFuxALW3e5+z7pujVZ7DjPIrvyYhZ2rh+g5OUFPG5m63kyz0sj4B2IBcsm5liHMtKlvWjb4IL0QgMvWPeSVfecoF+YSIj5Uvo+D+HaXUWXAQrEGscfiedqVTNb1autKoapOLy53XmR3X2p1ygjEymc7fWJFLpwNrFY+WfCxPQXAOn5GlVIybpO5h+kbUgBYdI0ZjTtjsC7xWnIaJ1518x2A75BCFEDjjOzT7v7T2ramunufx04/qqpY9sI/XnywYyyh+zzNSP9f6bp/zuBY9z9OAsb6jryi1szCdXSbiVlveT/ou95uk7RMyP6mRZ233+iOAMDMOvBWMbdj0668GeIl/pllKcVfy8DzjJptPPeJMDL2nor8WJ79cDLZNLg/nL77bIgnecaIlxjpvNdkFgI27SsQgshOAtrYbWQa6eTisPdL7fwbG1qd/98UkU9QTg+5Bd567LlNMbDgesaUtqhnMCfQOh+O1MnfK81s/OIN9/iRK6ozL5zTPW9OVYY2PcLlKf7zujipvlfRAS1P8Gs0fPVRHD2Ku4xsz2J6chqhMvlLyvKL+Tutw8I6yausQDbWji47EvoqE8lrBeqeNEiSPz7GAoKMm9dQ94uOHXZCNYIb6iyNrpO0ScnHeLJxJT7b1R7Fx1Dil7m7lcRsSewiIh2DAXBUrzCIcKrYyr/gXiRvJ3hwednEKO58WCB/GJbGqUXChwzu8ndN7eR5p9NgjQ1tloYoLWKw8JK58Pk4nibWVUc79aJFLriBcF9vFnEtUrqhO/HCd3KckTG1exELMtQLqOxpkuchi5umhMG1Ax/oZnL6gHEsT9PTOevoHoU2ypCfx5339PMdidMW/5OBPCpC66+DzH6/4q7T08qkR/V1MlWsg+jWeD7qhFskxFt4yk6gA+FMPyuhV3xJK8OYr1S0e/uPjktpo0ZHvFLpprZWRWCYqx51sw28GTnbGZZgPki9kr97DLafs7dnzMzLBZWH7AI/1hHFxXHicQg4YT0/T1pW+G6krvfamF59E+PPGxrEyaWD7j7iAw1cyKtTM0sXBq3IGxXK1PMjKpTcTNlcRpu9Jo4DVbspnm4V+RKM7NvEItR+cj+07w+otT6df0ZKD+aCP2rEYsHdxMpnO4DDvaIbzumWLfA94Uj2MFtud+yKfpuDKUrgrhea7v7G0vqXePu29Zty/32kLuv2va30ZDuwS8z5HXWZGTZta2NCJOnbD1mOSKr9YgXnw3Px3a+D4+vXdfOhcTL/OOEquEpYF53r1w/6IIVuM0Xbcv9dhix8DqRmNm8iVAhbkd4oX5lrPs45nh1uuSfEdHvIS7wHwl71fuAj1fVHc2H8FB5FaGCWIEw62q7j8L+EYbjm6X/dyaCbf8Psaq/SoP9XkcYWH8Z+LcW/VmYWMCaSAjfJnUeALZN/xvwSWrS2xPehz9J1+jh7NOgrSlNtg38PiJdd9G23G/rEuqQ36a/2WdnYPGC8gsQ5m5TCbVXlvJ8JeD+inbOBj5UsH1f4NxxumcfIl7mNh77H2hrfmKUuA6xGDgvMH9J2buK/u/Q5paEamW+BmU3JuJ9/41QG74EPFN3L+WfP0KnX3Uv3Z3kxEKETn9S2r4gNWng55RP3Um8N/f/5wiTJZIQGZcDJKb1fybcGKelk9y6LWJ0XrT9Z0Rc2MHtGwKXNNz3soSu9+bUv88XlJlETKWPJzyCDPgYsZD104btTCrYtlpNnZsIk5hpxCjscCJYS11btxCqpez7ZsAtJWXfSswwniBcoLPPDwirkbq25m14/AcxFJdheu4zFfhYRb1lCD389cRC4jcJNcotwLLjdN9eR6iyxnzfBW01funlt1cJs4J6E4B7OvZvMjHIuSsJyH2Ar9bU2Zaw1b8+XatHgK0rype+VKgZNMwpn7qTOCX3/zXE1GZcD5AYQbxyDPbzWMn20huKCJTRpo3XETrqFwp++2kSRh8m7KWvSjfVeg32e0ju/10Hfqu7ie8YPBYiU21dm+smofZI+txFwUsqV7bxCLag/g5p/08So5YZVIyMgAM63gNbEy/zAwg32TG/X3NtbUTYsh5KhE09mFARjWUbyxJONvcTziMbpM9WhK6zqM5LuXM8M/1fe85T3TPpNuucnP5Oy237ZYN68xOzh3UpGcnnyt5GLGZD7qVH2BQ3fsn0+albcHvMIlrQ79JFvhzAwsOrdgW9I13iNBRRpswuSx0O5UF/ZmFmaxH64V2IRbpzCXXAIK/1FK7PIifYn4kbuYnX3rsJ7yIYuRC1PdV5yJ5Ltpa/NrOPEVl/l644nhXc/VEvCHxfVsdHv8h0DCGo7/b0xNTwPQv331YZrT2yn1zXoX9d+AoxzV6A5l6WbWmdm87d6wIqVdHaaiHxd4vg61PN7ChCXVnl4NLF2mELH/KszAesmpcYCMzx1KURWho4grgI3/GUtNDCzfgN7n50aeWuHWoRp6HAfGbWT4SDyIiXi5mdDVzr7icPbN+XSH2ye03/biNUF9cToR6fKyk3LB7A4PeaNvLxe4f50A9+L6i7ETEyWozQSy8KHOUlubBGuSDTaZHJwutp24GHpqp844zWfWEptc9saqtLbrou7WxZtN1rbIYtvAKfIF5CnyBUcCf68CS8g3Xm+Gs81sxRgXVg1irmCLybC3HR/pchwjS+wJBd5obEjfJOL0kaaeE181XCS+pRko0rkW/uvwbf0Gb2EjFayAx8FyTMxZrEDs0LxM5CvAlVgr5B3YdoN4LN6m1ECO0bqHjBWnLrbLsS3gcWcYCv9eqsyqNtY293/5FF0PoR57togDI7MbN3ENlDvpO+30bMupxQpZXa0M8N13isqQus0zrV8mgZKyFbsf8ngE3T6D2L8vRzd7+2puo3iIXGlX3I+24SEefhaIay3WbtjGa6t66Fy6kxMr5DodpkFNfKS/5vwmOEDr1tvaZT9NsJdVfjjNY9sj9wiEWOshcZH1OzbOpeFBZzzEdRZrYxsbC6FnGd5gGerTimQwiVWcb8hI56EWKQUuXANDdc4zGlTufbJdXyqLAOcRq60EEfuAOwel7QeCQE/QhhEnbQYAXrGMqvo+Dueq2qBH2d8DgEuNTCm7BRKM/EEt4s/Up2DJ8CrrPhfv+jSu461vjoXYab8PPU1ogBikXAp7HmeEKY/piYHb6X6qSg87n7Y7nvN3lEBHvSSoIaWSTUvRn4LOFROz39tBIxy3zZUid8l2Uo1fKezJ5Uy63jNMwmvGiE55HdonDU4d1D+XWh07Ua5Qi96yLT1Wb2lgZT9KVsKNrd90gjr9Te+sy+xbRaLLIeT3H3Zy2SwW5AxNYYy+t+jZn9u6dkA7m29wE+T31mita4+0NmNo9H0JrTzKzKlX7xgbofy30ti1C2PJGkcy3gfwkLmDuA07wk79vLhbrU8aNKtdyRrum0x5v7zOy9PhBDNj1oD1TU67pi3IqerlXTEewgTafo8xBT1vwoPptyz46RZhtOJGYR6xIzglMIM8TCRauOfIKIj/s2d/81kIUf3XOM28loa7Vwm5l9qGAx+8OUxOLwlPUktbMh4Qm6CbC/mT3t3TN/z/HUhl6zjqmWR0HXdNrjzf7ABWb2AeLN7IRt54JE/IkyxlWHnaeHa9V0BDuMFlP0P7r7ER361Qcz3d3TotOxaQAxpiZP7n5pemFdZmY7EXEPNiLMrp4ay7YS7yGcLfYnBP/yRB63Mj4BXGQReCrLr/cGQve7U01bCxJWEYumzx+oTlU011NnatY51XLnDnWI0zA7MbNtCH20ER6A1/TcJaC3azWDGAm1WmRqOkVva33RJ2l2djmhi96CUJVN8XFIzW6Rl+4iwotvtzJzx1Hsv7PVQiqfPSMQz0jpYraZnZTKziDWKm4loqiNx8tkjqJO+HZOtTyWmNnH3f2Y2dHWWNNhxbhrO3PEtWqCmU0jvJheT0zNTwF2dvctB8ot4d1SIs12zGxZYvr/K3f/hZmtAGw1qKYaZRv5RLbzEy+8lxjja2xmNxPerI+l71OIwDqLELrYwoBGHdu6nAiXeg/xMrmFbhY0cx1znJ1vEWb2qLuXpqqfkzGzyRSsGHuLxIBzKl0XmTJbZYs8XL9PU/QxtV/uEzNbEvjL3CpALCXAzH0/Pls8M7Nb3X3jMW7PiNHvpumzDrHwdou7F9r9vxwYTR772cm4m7iNJx6ePfO4+0vufhrhi/9y4ERiUSZbZPotMZKtY0ZaKNob+LlFho7xclcfV8xsYzO73swuMLP1zeweYhT3hJlt33f/OtLFaqEzHtxDZBm5jDA9W4UC882XE3OL8J0rRxCJbMV4ipkdZWafoMbPfS5iZhrdZYtMx9LMCmF3Qk+8r4dH4asJJ5a5keMJz8eziUwvH3T3ZQm975F9dmwU3GaR824YVVYLXTGzA83sHDN7jMjVuAPwIOE5WZg9++XCHKN2sA5xGuYGbKSf+6LACV7h5z63MBaLTC+DKfoUd18v/X+/u6+V+22uWTDMYxHT5SLiBTnCasHDS3Ss2voWoeu92d0bZXh5uTDHCN+XMxZR4FZw9wf77stY0naRKS0+fo3Q532ZUFEsSczA3uvudenF5zhsNsbhmN20sVoQ7ZHwHWeS2+fRhOvlyma2HpEbbczjYvRJkxFsWnz8HDH6Pwl4q0curjUJb7y5cZSYD6CUBU8ifV/A3edKXbYYf+YWne/czOHAG4GnAdx9CvXZmOdoRrHINNHdr/TI8fa4pzCX7l7lIThH4+7zuPskd3+Fu09M/2ffJXhFKXOlHnUuY6a7/9VsrjbYGOR4hkaw1zIwgiUF3S8gH793MNuupmDiXwoJ33HCzC4l3DLvSe6W81hkIz6QWGCYm5noQ4H1j8iPYGteMq1DZQrxckVqh/HjB8AVRD60dYiV47OIFElzu/1ipxGspuhCDKEFt3HEIobpF4m8a2cwJJjce846MBq0yCTE6JHaYXx5kRBS8xN+8S+LN52PLgawEAIJ33Ejrfp/C7gY2MDd/15TRQjxL4TUDuOEmf0C+E8f36wfQoi5FAlfIYToAVk7CCFED0j4CiFED0j4CiFED0j4CiFED0j4CiFED/x/SIYhOhFXwfYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb3f7160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 75)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0         Lvl    AllPub    Inside  ...           0             0         0   \n",
       "1         Lvl    AllPub    Corner  ...          36             0         0   \n",
       "2         Lvl    AllPub    Inside  ...          34             0         0   \n",
       "3         Lvl    AllPub    Inside  ...          36             0         0   \n",
       "4         HLS    AllPub    Inside  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         120        0       0       6    2010        WD         Normal  \n",
       "1           0        0   12500       6    2010        WD         Normal  \n",
       "2           0        0       0       3    2010        WD         Normal  \n",
       "3           0        0       0       6    2010        WD         Normal  \n",
       "4         144        0       0       1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 76)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 236)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 176)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160         21.0     1936            4            7       1970   \n",
       "1455         160         21.0     1894            4            5       1970   \n",
       "1456          20        160.0    20000            5            7       1960   \n",
       "1457          85         62.0    10441            5            5       1992   \n",
       "1458          60         74.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0             2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1             1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2             2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3             1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4             2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "...            ...         ...         ...         ...  ...   ...   ...  ...   \n",
       "1454          1970         0.0         0.0         0.0  ...     0     0    1   \n",
       "1455          1970         0.0       252.0         0.0  ...     0     0    1   \n",
       "1456          1996         0.0      1224.0         0.0  ...     0     0    1   \n",
       "1457          1992         0.0       337.0         0.0  ...     0     0    1   \n",
       "1458          1994        94.0       758.0         0.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 176 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1          1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2          2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3          1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4          2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 176)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 11.8min\n"
     ]
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-eca6a411e888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_Test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'regressor' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
       "       230294.19 ], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2c66b482779b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##Create Sample Submission file and Submit using ANN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msub_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
